{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2187d-e0da-4cc8-b4ec-aa4eed372163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2025 Thousand Brains Project\n",
    "#\n",
    "# Copyright may exist in Contributors' modifications\n",
    "# and/or contributions to the work.\n",
    "#\n",
    "# Use of this source code is governed by the MIT\n",
    "# license that can be found in the LICENSE file or at\n",
    "# https://opensource.org/licenses/MIT.\n",
    "\n",
    "import os\n",
    "from tbp.monty.frameworks.utils.logging_utils import load_stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tbp.monty.frameworks.utils.plot_utils import plot_graph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467a4f1-cab6-4587-b7ac-7547681de21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce9078-ad08-424c-b5da-34157b034680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains the pretrained models trained in simulation; accessed via e.g. \n",
    "# model = lm_models['pretrained'][0]['potted_meat_can']['patch']\n",
    "pretrain_path_simulated_data = os.path.expanduser(\"~/tbp/results/monty/pretrained_models/\")\n",
    "pretrained_dict_simulated_data = pretrain_path_simulated_data + \"pretrained_ycb_v10/surf_agent_1lm_tbp_robot_lab/pretrained/\"\n",
    "\n",
    "# Contains the additionally trained models from the Crete hackathon, e.g.\n",
    "# model = lm_models_crete_data['0']['LM_0']['new_object0']['patch']\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/evidence_eval_runs/logs/\")\n",
    "exp_name_crete_data = \"json_dataset_ultrasound_learning\"\n",
    "exp_path_crete_data = log_path + exp_name_crete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7ddb4-fd36-4f09-a915-96b750984797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from the Crete hackathon\n",
    "\n",
    "train_stats, eval_stats, detailed_stats, lm_models_crete_data = load_stats(exp_path_crete_data,\n",
    "                                                                load_train=False, # doesn't load train csv\n",
    "                                                                load_eval=False, # loads eval_stats.csv\n",
    "                                                                load_detailed=False, # doesn't load .json\n",
    "                                                                load_models=True, # loads .pt models\n",
    "                                                                pretrained_dict=pretrained_dict_simulated_data,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad77983-bd4f-4d37-8986-e1e90cb91309",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_crete_data = lm_models_crete_data['0']['LM_0']['new_object0']['patch']\n",
    "locs_crete_data = np.array(model_crete_data.pos)\n",
    "normals_crete_data = np.array(model_crete_data.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a474670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from more refined ultrasound pipeline\n",
    "exp_name_refined_data = \"json_dataset_ultrasound_learning_new_meat_can\"\n",
    "exp_path_refined_data = log_path + exp_name_refined_data\n",
    "\n",
    "# Load the results from the Crete hackathon\n",
    "\n",
    "_, _, _, lm_models_refined_data = load_stats(exp_path_refined_data,\n",
    "                                            load_train=False, # doesn't load train csv\n",
    "                                            load_eval=False, # loads eval_stats.csv\n",
    "                                            load_detailed=False, # doesn't load .json\n",
    "                                            load_models=True, # loads .pt models\n",
    "                                            pretrained_dict=pretrained_dict_simulated_data,\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7579b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_refined_data = lm_models_refined_data['0']['LM_0']['new_object0']['patch']\n",
    "locs_refined_data = np.array(model_refined_data.pos)\n",
    "normals_refined_data = np.array(model_refined_data.norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"artifacts\" if desired (i.e. poorly learned points)\n",
    "# not_artifacts = np.where(locs[:,2] > -0.7)\n",
    "# locs = locs[not_artifacts]\n",
    "# normals = normals[not_artifacts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1564b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph_with_normals(locations, normals):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "    # color points by id in array\n",
    "    colors = np.linspace(0, 1, len(locations))\n",
    "    ax.scatter(locations[:,0], locations[:,1], locations[:,2], c=colors)\n",
    "    # add point normals to plot\n",
    "    ax.quiver(locations[:,0], locations[:,1], locations[:,2], normals[:,0], normals[:,1], normals[:,2], length=0.01, color=\"red\")\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"z\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec391f8-5fc6-4755-a32c-52cf461878cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph_with_normals(locs_crete_data, normals_crete_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph_with_normals(locations=locs_refined_data, normals=normals_refined_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_models_refined_data['pretrained'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf71f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simulation_data = lm_models_crete_data['pretrained'][0]['potted_meat_can']['patch']\n",
    "locs_simulation_data = np.array(model_simulation_data.pos)\n",
    "normals_simulation_data = np.array(model_simulation_data.norm)\n",
    "\n",
    "plot_graph_with_normals(locations=locs_simulation_data, normals=normals_simulation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc63c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultrasound_perception",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
